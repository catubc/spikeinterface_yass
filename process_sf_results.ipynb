{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sfsortingresults import SFSortingResults\n",
    "import spikewidgets as sw\n",
    "\n",
    "import spikeextractors as se\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "#\n",
    "from ProcessSorts import ProcessSorts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate a `SFSortingResults` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SFSortingResults` object allows you to easily retrieve studies, recording names, and available sorted results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start kachery daemon\n",
    "os.system(\"kachery-p2p-start-daemon --label test & \")\n",
    "\n",
    "# join correct channel\n",
    "os.system(\"kachery-p2p-join-channel https://gist.githubusercontent.com/magland/0a732d4562ec87d0f1b9baf7eed2718d/raw/spikeforest-download-channel.yaml &\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5094 sorting outputs\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "sfresults = SFSortingResults()\n",
    "\n",
    "# Optional \n",
    "# study_names = sfresults.get_study_names()\n",
    "# print(f\"Available studies:\\n{study_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/spikesorting/sorting_analysis/\n",
      "Recording 006_synth has the following sorting outputs:\n",
      "['IronClust', 'JRClust', 'KiloSort', 'KiloSort2', 'Klusta', 'MountainSort4', 'SpykingCircus', 'Tridesclous']\n",
      "sorter selected:  IronClust\n",
      "WARNING: load_object() is deprecated. Use load_json() instead.\n",
      "\n",
      "sorter selected:  JRClust\n",
      "WARNING: load_object() is deprecated. Use load_json() instead.\n",
      "error in extracting sorter:  'float' object has no attribute 'startswith'\n",
      "\n",
      "sorter selected:  KiloSort\n",
      "WARNING: load_object() is deprecated. Use load_json() instead.\n",
      "\n",
      "sorter selected:  KiloSort2\n",
      "WARNING: load_object() is deprecated. Use load_json() instead.\n",
      "\n",
      "sorter selected:  Klusta\n",
      "WARNING: load_object() is deprecated. Use load_json() instead.\n",
      "\n",
      "sorter selected:  MountainSort4\n",
      "WARNING: load_object() is deprecated. Use load_json() instead.\n",
      "\n",
      "sorter selected:  SpykingCircus\n",
      "WARNING: load_object() is deprecated. Use load_json() instead.\n",
      "\n",
      "sorter selected:  Tridesclous\n",
      "WARNING: load_object() is deprecated. Use load_json() instead.\n",
      "\n",
      "/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/spikesorting/sorting_analysis/ synth_mearec_neuronexus_noise10_K10_C32 006_synth\n"
     ]
    }
   ],
   "source": [
    "import glob2\n",
    "import numpy as np\n",
    "\n",
    "#fnames_sorted_yass = glob2.glob('/media/cat/1TB/spikesorting/sorting_data/recordings_yass_sorted/*.npz')\n",
    "fnames_sorted_yass = glob2.glob('/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/spikesorting/final_sorts_npz/*.npz')\n",
    "# \n",
    "dir_analysis = '/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/spikesorting/sorting_analysis/'\n",
    "\n",
    "for fname in fnames_sorted_yass:\n",
    "    #id_ = 1\n",
    "    #fname_yass = fnames_sorted_yass[id_]\n",
    "\n",
    "    p = ProcessSorts(fname,\n",
    "                     sfresults,\n",
    "                     dir_analysis)\n",
    "\n",
    "    if p.study_exists:\n",
    "        #\n",
    "        p.extract_all_sorts()\n",
    "\n",
    "        # \n",
    "        p.run_GTstudy()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hybrid_drift_siprobe' 'hybrid_drift_tetrode' 'hybrid_static_siprobe'\n",
      " 'hybrid_static_tetrode' 'manual_tetrode_1200s' 'manual_tetrode_2400s'\n",
      " 'manual_tetrode_600s' 'mea_c30' 'neurocube_quiroga_difficult1'\n",
      " 'neurocube_quiroga_difficult2' 'neurocube_quiroga_easy1'\n",
      " 'neurocube_quiroga_easy2' 'neurocube_sim2_11K20' 'neurocube_sim2_2K10'\n",
      " 'paired_boyden32c' 'paired_crcns' 'paired_english' 'paired_kampff'\n",
      " 'paired_mea64c' 'paired_monotrode_boyden32c' 'paired_monotrode_crcns'\n",
      " 'paired_monotrode_kampff' 'paired_monotrode_mea64c' 'synth_bionet_drift'\n",
      " 'synth_bionet_shuffle' 'synth_bionet_static'\n",
      " 'synth_magland_noise10_K10_C4' 'synth_magland_noise10_K10_C8'\n",
      " 'synth_magland_noise10_K20_C4' 'synth_magland_noise10_K20_C8'\n",
      " 'synth_magland_noise20_K10_C4' 'synth_magland_noise20_K10_C8'\n",
      " 'synth_magland_noise20_K20_C4' 'synth_magland_noise20_K20_C8'\n",
      " 'synth_mearec_neuronexus_noise10_K10_C32'\n",
      " 'synth_mearec_neuronexus_noise10_K20_C32'\n",
      " 'synth_mearec_neuronexus_noise10_K40_C32'\n",
      " 'synth_mearec_neuronexus_noise20_K10_C32'\n",
      " 'synth_mearec_neuronexus_noise20_K20_C32'\n",
      " 'synth_mearec_neuronexus_noise20_K40_C32'\n",
      " 'synth_mearec_tetrode_noise10_K10_C4'\n",
      " 'synth_mearec_tetrode_noise10_K20_C4'\n",
      " 'synth_mearec_tetrode_noise20_K10_C4'\n",
      " 'synth_mearec_tetrode_noise20_K20_C4']\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Study 'LONG_STATIC_600s_16c' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cbbaf036cdd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msfresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_study_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m sfresults.get_sorting_output_names(target_study,\n\u001b[0;32m----> 9\u001b[0;31m                                   target_recording)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/spikeinterface_yass/sfsortingresults.py\u001b[0m in \u001b[0;36mget_sorting_output_names\u001b[0;34m(self, study_name, recording_name)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# get study\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"studyName == '{study_name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Study '{study_name}' not found\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# get recording\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Study 'LONG_STATIC_600s_16c' not found"
     ]
    }
   ],
   "source": [
    "\n",
    "# show all studies loaded by \n",
    "print(np.sort(sfresults.get_study_names()))\n",
    "\n",
    "# search for an already sorted yass study\n",
    "data_yass = np.load('/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/spikesorting/final_sorts_npz/LONG_STATIC_600s_16c_010_synth.npz')\n",
    "target_study = data_yass['study_name']\n",
    "target_recording = data_yass['rec_name']\n",
    "sfresults.get_sorting_output_names(target_study,\n",
    "                                  target_recording)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%debug\n",
    "from spikecomparison import GroundTruthStudy\n",
    "import glob2\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "study_folder = '/media/cat/1TB/spikesorting/sorting_analysis/hybrid_static_siprobe/rec_32c_600s_11/'\n",
    "study = GroundTruthStudy(study_folder)\n",
    "\n",
    "# fix the ground truth sampling frequency\n",
    "fnames = glob2.glob(study_folder+ 'sortings/*.npz')\n",
    "sf = np.load(fnames[0])['sampling_frequency']\n",
    "\n",
    "gt_data = np.load(study_folder+'/ground_truth/rec0.npz')\n",
    "np.savez(study_folder+'/ground_truth/rec0.npz',\n",
    "        unit_ids = gt_data['unit_ids'],\n",
    "        spike_labels = gt_data['spike_labels'],\n",
    "        spike_indexes = gt_data['spike_indexes'],\n",
    "        sampling_frequency = sf)\n",
    "\n",
    "\n",
    "# \n",
    "study.run_comparisons(exhaustive_gt=True, \n",
    "                      match_score=0.0,\n",
    "                      delta_time=3.0)\n",
    "\n",
    "# \n",
    "comparisons = study.comparisons\n",
    "dataframes = study.aggregate_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_name</th>\n",
       "      <th>sorter_name</th>\n",
       "      <th>num_gt</th>\n",
       "      <th>num_sorter</th>\n",
       "      <th>num_well_detected</th>\n",
       "      <th>num_redundant</th>\n",
       "      <th>num_overmerged</th>\n",
       "      <th>num_false_positive</th>\n",
       "      <th>num_bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rec0</td>\n",
       "      <td>HerdingSpikes2</td>\n",
       "      <td>74</td>\n",
       "      <td>70</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rec0</td>\n",
       "      <td>MountainSort4</td>\n",
       "      <td>74</td>\n",
       "      <td>119</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rec0</td>\n",
       "      <td>KiloSort2</td>\n",
       "      <td>74</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rec0</td>\n",
       "      <td>SpykingCircus</td>\n",
       "      <td>74</td>\n",
       "      <td>41</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rec0</td>\n",
       "      <td>KiloSort</td>\n",
       "      <td>74</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rec0</td>\n",
       "      <td>IronClust</td>\n",
       "      <td>74</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rec0</td>\n",
       "      <td>JRClust</td>\n",
       "      <td>74</td>\n",
       "      <td>47</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rec0</td>\n",
       "      <td>yass</td>\n",
       "      <td>74</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rec_name     sorter_name num_gt num_sorter num_well_detected num_redundant  \\\n",
       "0     rec0  HerdingSpikes2     74         70                20             0   \n",
       "1     rec0   MountainSort4     74        119                22             7   \n",
       "2     rec0       KiloSort2     74         30                24             0   \n",
       "3     rec0   SpykingCircus     74         41                26             0   \n",
       "4     rec0        KiloSort     74         38                30             0   \n",
       "5     rec0       IronClust     74         32                30             0   \n",
       "6     rec0         JRClust     74         47                24             0   \n",
       "7     rec0            yass     74         64                32             0   \n",
       "\n",
       "  num_overmerged num_false_positive num_bad  \n",
       "0              3                  0       0  \n",
       "1              0                 38      45  \n",
       "2              2                  0       0  \n",
       "3              1                  0       0  \n",
       "4              1                  0       0  \n",
       "5              0                  0       0  \n",
       "6              1                  0       0  \n",
       "7              0                  0       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparison summary\n",
    "dataframes['count_units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30000.]\n",
      "[30000.]\n"
     ]
    }
   ],
   "source": [
    "data = np.load(study_folder+'/ground_truth/rec0.npz')\n",
    "print (data['sampling_frequency'])\n",
    "\n",
    "data = np.load(study_folder+'/sortings/rec0[#]yass.npz')\n",
    "print (data['sampling_frequency'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL UNIT MATCHING CODE\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "import numpy as np\n",
    "\n",
    "def find_nearest_ids(s, times, max_diff):\n",
    "    \n",
    "    diff = np.abs(times-s)\n",
    "    idx = np.where(diff <= max_diff)[0]\n",
    "    return idx\n",
    "        \n",
    "        \n",
    "def match_unit(gt_spikes, \n",
    "               gt_ids,\n",
    "               times,\n",
    "               sorted_ids,\n",
    "               max_diff=100):\n",
    "    \n",
    "    n_gt_units = np.unique(gt_ids).shape[0]\n",
    "    #print (\"n units: \", n_gt_units)\n",
    "    \n",
    "    ctr=0\n",
    "    row = np.zeros(n_gt_units,  'int32')\n",
    "    for s in times:\n",
    "        idx = find_nearest_ids(s, gt_spikes, max_diff)\n",
    "#         print (idx)\n",
    "#         print (gt_ids[idx])\n",
    "        row[gt_ids[idx]]+=1\n",
    "        \n",
    "    return row\n",
    "        \n",
    "\n",
    "# \n",
    "import glob2\n",
    "root_dir = '/media/cat/1TB/spikesorting/sorting_analysis/synth_mearec_neuronexus_noise10_K10_C32/004_synth/sortings/'\n",
    "fnames = glob2.glob(root_dir+'/*.npz')\n",
    "\n",
    "for fname in fnames:\n",
    "    print (os.path.split(fname)[1])\n",
    "    \n",
    "    #\n",
    "    fname_gt = os.path.split(fname)[0].replace('sortings','ground_truth/')+'rec0.npz'\n",
    "    gt_data = np.load(fname_gt)\n",
    "    gt_times = gt_data['spike_indexes']\n",
    "    gt_ids = gt_data['spike_labels']-1 # convert to 0-based idnex\n",
    "\n",
    "    \n",
    "    # \n",
    "    sorted_data = np.load(fname)\n",
    "    sorted_times = sorted_data['spike_indexes']\n",
    "    sorted_ids = sorted_data['spike_labels']\n",
    "    sorted_units = np.unique(sorted_ids)\n",
    "\n",
    "    # \n",
    "    #print (\"# of gt spikes: \", gt_ids.shape)\n",
    "    for unit in sorted_units:\n",
    "        idx = np.where(sorted_ids==unit)[0]   \n",
    "\n",
    "        unit_times = sorted_times[idx] \n",
    "        #print (\"unit times: \", unit_times.shape)\n",
    "\n",
    "        row = match_unit(gt_times,\n",
    "                         gt_ids,\n",
    "                         unit_times,\n",
    "                         sorted_ids,\n",
    "                         max_diff = 100)\n",
    "        print (\"ROW: \", row)\n",
    "        match = row/gt_ids.shape[0]\n",
    "        best_match = np.argmax(match)\n",
    "        print (\"      match: \", unit, best_match, np.round(match[best_match],3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
